{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exp-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAND Predictions: [1 1 1 0]\n",
      "XOR Predictions: [1 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np  # Importing numpy for numerical operations\n",
    "\n",
    "# Step function acts as an activation function, returns 1 if input >= 0 else 0\n",
    "def step_function(x):\n",
    "    return 1 if x >= 0 else 0\n",
    "\n",
    "# Function to train a perceptron\n",
    "def perceptron_train(X, y, lr=0.1, epochs=100):\n",
    "    np.random.seed(42)  # Setting seed for reproducibility\n",
    "    weights = np.random.rand(X.shape[1])  # Initializing weights randomly\n",
    "    bias = np.random.rand()  # Initializing bias randomly\n",
    "    \n",
    "    # Training for given number of epochs\n",
    "    for _ in range(epochs):\n",
    "        for i in range(X.shape[0]):  # Iterating over each training example\n",
    "            net_input = np.dot(X[i], weights) + bias  # Weighted sum of inputs and bias\n",
    "            output = step_function(net_input)  # Applying activation function\n",
    "            error = y[i] - output  # Calculating error\n",
    "            \n",
    "            # Updating weights and bias based on the error\n",
    "            weights += lr * error * X[i]\n",
    "            bias += lr * error\n",
    "    \n",
    "    return weights, bias  # Returning trained weights and bias\n",
    "\n",
    "# Function to make predictions using trained perceptron\n",
    "def perceptron_predict(X, weights, bias):\n",
    "    return np.array([step_function(np.dot(x, weights) + bias) for x in X])  # Applying step function to each input\n",
    "\n",
    "# NAND Truth Table (Inputs and expected outputs)\n",
    "X_nand = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])  # Inputs for NAND gate\n",
    "y_nand = np.array([1, 1, 1, 0])  # Expected outputs for NAND gate\n",
    "\n",
    "# XOR Truth Table (Inputs and expected outputs)\n",
    "X_xor = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])  # Inputs for XOR gate\n",
    "y_xor = np.array([0, 1, 1, 0])  # Expected outputs for XOR gate\n",
    "\n",
    "# Train Perceptron for NAND gate\n",
    "theta_nand, bias_nand = perceptron_train(X_nand, y_nand)  # Training on NAND dataset\n",
    "y_pred_nand = perceptron_predict(X_nand, theta_nand, bias_nand)  # Making predictions\n",
    "\n",
    "# Train Perceptron for XOR gate\n",
    "theta_xor, bias_xor = perceptron_train(X_xor, y_xor)  # Training on XOR dataset\n",
    "y_pred_xor = perceptron_predict(X_xor, theta_xor, bias_xor)  # Making predictions\n",
    "\n",
    "# Printing the predictions\n",
    "print(\"NAND Predictions:\", y_pred_nand)  # Expected: [1, 1, 1, 0]\n",
    "print(\"XOR Predictions:\", y_pred_xor)  # Expected: Incorrect output due to XOR non-linearity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
